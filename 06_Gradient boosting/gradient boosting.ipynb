{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В независимости построения деревьев в случаном лесе кроется и плюс и минус алгоритма: с одной стороны, построение деревьев можно распараллеливать и, например, организовывать на разных ядрах процессора, с другой стороны, следствием их независимости является тот факт, что для решения сложных задач требуется очень большое количество деревьев. В этих случаях случаях (при большой выборке или большом количестве признаков) обучение случайного леса может требовать очень много ресурсов, а если для ограничения их потребления слишком ограничивать глубину деревьев, они могут не уловить все закономерности в данных и иметь большой сдвиг (и, следовательно, ошибку)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг является своеобразным решением этой проблемы: он заключается в последовательном построении ансамбля, когда деревья строятся одно за другим, и при этом каждое следующее дерево строится таким образом, чтобы исправлять ошибки уже построенного на данный момент ансамбля. При таком подходе базовые алгоритмы могут быть достаточно простыми, то есть можно использовать неглубокие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Общий подход градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый алгоритм ищется в виде **взвешенной суммы** базовых алгоритмов:\n",
    "\n",
    "$$a_{N}(x) = \\sum^{N}_{n=1}\\gamma_{n}b_{n}(x).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии задача состоит в минимизации среднеквадратичного функционала ошибки:\n",
    "\n",
    "$$\\frac{1}{l}\\sum_{i=1}^{l}(a(x_{i}) - y_{i})^{2} \\rightarrow \\text{min}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как ансамбль строится итеративно, нужно вначале обучить первый простой алгоритм:\n",
    "\n",
    "$$b_{1}(x) = \\underset{b}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i}) - y_{i})^{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая задача легко решается методом градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы нашли первый алгоритм $b_{1}(x)$, нам нужно добавить в ансамбль еще один алгоритм $b_{2}(x)$. Для начала найдем разницу ответов первого алгоритма с реальными ответами:\n",
    "\n",
    "$$s_{i}^{(1)} = y_{i} - b_{1}(x_{i}).$$\n",
    "\n",
    "Если прибавить эти значения к полученным предсказаниям, получим идеальный ответ. Таким образом, новый алгоритм логично обучать так, чтобы его ответы были максимально близки к этой разнице, чтобы при их прибавлении к ответам первого алгоритма мы получили близкие к реальным. Значит, второй алгоритм будет обучаться на следующем функционале ошибки:\n",
    "\n",
    "$$b_{2}(x) = \\underset{b}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i}) - s_{i}^{(1)})^{2} = \\underset{b}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i}) - (y_{i} - b_{1}(x_{i})))^{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый следующий алгоритм также настраивается на остатки композиции из предыдущих алгоритмов:\n",
    "\n",
    "$$b_{N}(x) = \\underset{b}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i}) - s_{i}^{(N)})^{2},$$ \n",
    "\n",
    "$$s_{i}^{(N)} = y_{i} - \\sum_{n=1}^{N-1}b_{n}(x_{i}) = y_{i} - a_{N-1}(x_{i}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, каждый новый алгоритм корректирует ошибки предыдущих, и так продолжается до момента получения приемлемой ошибки на композиции. Вектор коэффициентов $s$ при этом называют _вектором сдвига_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор сдвига из условия $s_{i} = y_{i} - a_{N-1}(x_{i})$ требует точного совпадения полученных предсказаний и ответов, однако, в более общем случае вектор сдвига принимают с учетом особенностей используемой в данном случае функции потерь: вектор сдвига должен ее минимизировать, то есть направлять в сторону уменьшения. Как мы помним из метода градиентного спуска, направление наискорейшего убывания функции совпадает с ее антиградиентом. Таким образом, если при обучении мы минимизируем функционал ошибки $L(y,z)$\n",
    "\n",
    "$$\\sum_{i=1}^{l}L(y_{i}, a_{N-1}(x_{i}) + s_{i}) \\rightarrow \\underset{s}{\\text{min}},$$\n",
    "\n",
    "сдвиг на каждом шаге должен быть противоположен производной функции потерь в точке $z = a_{N-1}(x_{i})$. \n",
    "\n",
    "$$s_{i} = \\left.-\\frac{\\partial L}{\\partial z} \\right|_{z = a_{N-1}(x_{i})}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый новый алгоритм таким образом выбирается так, чтобы как можно лучше приближать антиградиент ошибки на обучающей выборке. \n",
    "\n",
    "После того, как мы вычислили требуемый для минимизации ошибки сдвиг $s$, нужно настроить алгоритм $b_{N}(x)$ так, чтобы он давал максимально близкие к нему ответы, то есть обучать его именно на вектор сдвига. Близость ответов алгоритма к сдвигу обычно оценивается с помощью среднеквадратичной ошибки независимо от условий исхожной задачи (так как исходно используемая функция потерь $L$ уже учтена в сдвигах $s_{i}$):\n",
    "\n",
    "$$b_{N}(x) = \\underset{s}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i})-s_{i})^{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент $\\gamma$ для найденного алгоритма также находится по аналогии с наискорейшим градиентным спуском:\n",
    "\n",
    "$$\\gamma_{N} = \\underset{\\gamma}{\\text{argmin}}\\sum_{i=1}^{l}L(y_{i},a_{N-1}(x_{i}) + \\gamma b_{N}(x_{i})).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично алгоритму градиентного спуска, имеет смысл добавлять ответ каждого нового алгоритма не полностью, а с некоторым шагом $\\eta \\in (0, 1]$, так как базовые алгоритмы обычно достаточно простые (например, деревья малой глубины), и они могут плохо приближать вектор антиградиента, и тогда вместо приближения к минимуму мы будем получать случайное блуждание в пространстве. В градиентном бустинге такой прием называется сокращением шага.\n",
    "\n",
    "$$a_{N}(x) = a_{N-1}(x) + \\eta \\gamma_{N} b_{N}(x).$$\n",
    "\n",
    "Градиентный бустинг склонен к переобучению при увеличении числа итераций $N$ или глубины входящих в него деревьев. Стоит об этом помнить при построении алгоритма и выбирать оптимальные параметры по отложенной выборке или с помощью кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](gb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Алгоритм градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конечном итоге алгоритм построения модели градиентного бустинга заключается в следующих шагах:\n",
    "\n",
    "__1.__ Для инициализации выбирается произвольный простой алгоритм $b_{0}(x)$, в его роли можно брать обычные константные алгоритмы: в случае задачи регрессии это может быть\n",
    "\n",
    "$$b_{0}(x) = 0$$\n",
    "\n",
    "или среднее значение по всем объектам обучающей выборки \n",
    "\n",
    "$$b_{0}(x) = \\frac{1}{l}\\sum_{i=1}^{l}y_{i};$$\n",
    "\n",
    "в случае классификации - самый часто встречающийся в выборке класс\n",
    "\n",
    "$$b_{0}(x) = \\underset{y}{\\text{argmax}}\\sum_{i=1}^{l}[y_{i} = y].$$\n",
    "\n",
    "__2.__ Для каждой итерации вычисляется вектор сдвига $s$:\n",
    "\n",
    "$$s = \\left ( \\left.-\\frac{\\partial L}{\\partial z} \\right|_{z = a_{n-1}(x_{1})},...,\\left.-\\frac{\\partial L}{\\partial z} \\right|_{z = a_{n-1}(x_{l})}\\right );$$\n",
    "\n",
    "находится алгоритм\n",
    "\n",
    "$$b_{n}(x) = \\underset{s}{\\text{argmin}}\\frac{1}{l}\\sum_{i=1}^{l}(b(x_{i})-s_{i})^{2};$$\n",
    "\n",
    "находится оптимальный коэффициент $\\gamma$\n",
    "\n",
    "$$\\gamma_{n} = \\underset{\\gamma}{\\text{argmin}}\\sum_{i=1}^{l}L(y_{i},a_{n-1}(x_{i}) + \\gamma b_{n}(x_{i})).$$\n",
    "\n",
    "и добавляется в имеющийся ансамбль с умножением на шаг $\\eta$, называемый _скоростью обучения_ (опционально)\n",
    "\n",
    "$$a_{n}(x) = a_{n-1}(x) + \\eta \\gamma_{n} b_{n}(x).$$\n",
    "\n",
    "__3.__ При достижении критериев остановки компонуется итоговая модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Стохастический градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с градиентым спуском, есть стохастический градиентный бустинг, являющийся упрощенной (в плане потребления ресурсов) версией алгоритма. Его суть заключается в обучении каждого нового базового алгоритма на новой итерации не на всей обучающей выборке, а на некоторой ее случайной подвыборке. Практика показывает, что такой алгоритм позволяет получить такую же ошибку или даже уменьшить ее при том же числе итераций, что и в случае использования обычного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Примеры реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
