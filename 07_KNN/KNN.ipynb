{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть алгоритма k-ближайших соседей заключается в принципе отнесения объекту к тому классу, представители которого преобладают рядом с ним. \n",
    "Таким образом, упрощенно алгоритм классификации выглядит следующим образом:\n",
    "\n",
    "- найти расстояние от объекта $u$ до каждого из объектов $x$ обучающей выборки;\n",
    "- выбрать $k$ объектов, расстояние до которых минимально;\n",
    "- отнести объект к классу, к которому относится большинство из выбранных $k$ ближайших соседей:\n",
    "\n",
    "$$a(u) = \\underset{y}{\\text{argmax}}\\sum_{i=1}^{k}[y_{u}^{(i)}=y],$$\n",
    "\n",
    "то есть провести голосование.\n",
    "\n",
    "При этом метод можно адаптировать под регрессию: в этом случае находится не метка класса, а среднее значение ответа среди $k$ соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересной особенностью метода является то, что на этапе обучения не строится модель, а просто запоминается обучающая выборка. Вычисления начинаются именно на этапе решения задачи классификации конкретного объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логичным усовершенствованием алгоритма kNN является добавление соседям весов (так называемое \"взвешенное голосование\"), зависящих от их порядкового номера или расстояния до классифицируемого объекта (чем ближе объект обучающей выборки, тем больше его вес).\n",
    "\n",
    "От номера соседа $i$ веса можно определять как:\n",
    "\n",
    "- $w(i) = q^{i}$,   $q \\in (0,1)$;\n",
    "\n",
    "\n",
    "- $w(i) = \\frac{1}{i}$;\n",
    "\n",
    "\n",
    "- $w(i) = \\frac{1}{(i+a)^{b}}$;\n",
    "\n",
    "\n",
    "- $w(i) = \\frac{k + 1 - i}{k}$.\n",
    "\n",
    "\n",
    "От расстояния $d$ веса можно определять как:\n",
    "\n",
    "- $w(d) = q^{d}$,   $q \\in (0,1)$;\n",
    "\n",
    "\n",
    "- $w(d) = \\frac{1}{(d+a)^{b}}$, брать вес $\\frac{1}{d}$ по аналогии с номером соседа - неудачное решение, так как при $d = 0$ вес будет бесконечно большим, что приводит к переобучению\n",
    "\n",
    "\n",
    "- $w(d) = \\begin{cases}\n",
    "\\frac{d(z_{k}, x) - d(z_{i}, x)}{d(z_{k}, x) - d(z_{1}, x)}, & d(z_{k}, x) \\neq d(z_{1}, x) \\\\ \n",
    "1, & d(z_{k}, x) = d(z_{1}, x)\n",
    "\\end{cases}$.\n",
    "\n",
    "Существуют и другие способы вычисления весов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто перед работой по алгоритму kNN требуется проводить нормализацию признаков, так как они могут иметь разные единицы измерения, что может искажать расстояние между объектами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем и целом получается, что при работе с алгоритмом kNN исследователю требуется подобрать три параметра - количество соседей k, метрика расстояния и способ вычисления весов. Для получения лучшего качества работы алгоритма эти параметры нужно подбирать на отложенной выборке или при помощи кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
